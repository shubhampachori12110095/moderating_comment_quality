{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import re\n",
    "from collections import Counter\n",
    "import time\n",
    "import pickle\n",
    "import operator\n",
    "\n",
    "from pymongo import MongoClient\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation, TruncatedSVD\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from textblob import TextBlob\n",
    "from nltk.corpus import stopwords\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# timing function\n",
    "def timefunc(f):\n",
    "    def f_timer(*args, **kwargs):\n",
    "        start = time.time()\n",
    "        result = f(*args, **kwargs)\n",
    "        end = time.time()\n",
    "        print(f.__name__, 'took', end - start, 'seconds')\n",
    "        return result\n",
    "    return f_timer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get pickled sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('master.pkl','rb') as p:\n",
    "    com_trans = pickle.load(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>transcript</th>\n",
       "      <th>com_tran_list</th>\n",
       "      <th>TED=1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Transgenderism is a mental fucking disease ! N...</td>\n",
       "      <td>(Music) (Applause) Trevor Copp: When \"Dancing ...</td>\n",
       "      <td>[Transgenderism is a mental fucking disease ! ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is a wonderfully informative and hopeful ...</td>\n",
       "      <td>Thank you so much, Chris. And it's truly a gre...</td>\n",
       "      <td>[This is a wonderfully informative and hopeful...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>As you are a Climate Change denier, I feel obl...</td>\n",
       "      <td>Thank you so much, Chris. And it's truly a gre...</td>\n",
       "      <td>[As you are a Climate Change denier, I feel ob...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>if this started migrating itself into a normal...</td>\n",
       "      <td>(Music) (Applause) Trevor Copp: When \"Dancing ...</td>\n",
       "      <td>[if this started migrating itself into a norma...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We are applauding our own absence is a powerfu...</td>\n",
       "      <td>(Music) (Applause) Trevor Copp: When \"Dancing ...</td>\n",
       "      <td>[We are applauding our own absence is a powerf...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  \\\n",
       "0  Transgenderism is a mental fucking disease ! N...   \n",
       "1  This is a wonderfully informative and hopeful ...   \n",
       "2  As you are a Climate Change denier, I feel obl...   \n",
       "3  if this started migrating itself into a normal...   \n",
       "4  We are applauding our own absence is a powerfu...   \n",
       "\n",
       "                                          transcript  \\\n",
       "0  (Music) (Applause) Trevor Copp: When \"Dancing ...   \n",
       "1  Thank you so much, Chris. And it's truly a gre...   \n",
       "2  Thank you so much, Chris. And it's truly a gre...   \n",
       "3  (Music) (Applause) Trevor Copp: When \"Dancing ...   \n",
       "4  (Music) (Applause) Trevor Copp: When \"Dancing ...   \n",
       "\n",
       "                                       com_tran_list  TED=1  \n",
       "0  [Transgenderism is a mental fucking disease ! ...      0  \n",
       "1  [This is a wonderfully informative and hopeful...      1  \n",
       "2  [As you are a Climate Change denier, I feel ob...      1  \n",
       "3  [if this started migrating itself into a norma...      0  \n",
       "4  [We are applauding our own absence is a powerf...      0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(com_trans.shape)\n",
    "com_trans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df['TED=1'][230000:280000].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_comments = list(com_trans.comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments = all_comments\n",
    "len(comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transcripts - pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "names = nltk.corpus.names\n",
    "male_names = names.words('male.txt')\n",
    "female_names = names.words('female.txt')\n",
    "male_names = [w.lower() for w in male_names]\n",
    "male_names_plur = [(w.lower() + \"s\") for w in male_names]\n",
    "female_names_plur = [(w.lower() + \"s\") for w in female_names]\n",
    "female_names = [w.lower() for w in female_names]\n",
    "stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selected_words = ['',\n",
    "                  'laughter',\n",
    "                  'applause',\n",
    "                  'aa',\n",
    "                  'aaa',\n",
    "                  'aaaaa',\n",
    "                  'aaaaaah',\n",
    "                  'aaaah',\n",
    "                  'aah',\n",
    "                  'ab',\n",
    "                  'ababa',\n",
    "                  'abacha',\n",
    "                  'aback',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stoppers = set(list(stopwords) + list(selected_words) + list(ENGLISH_STOP_WORDS) + \n",
    "               list(female_names) + list(male_names) + list(female_names_plur) + list(male_names_plur))\n",
    "stoppers = list(stoppers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import csv\n",
    "\n",
    "# with open('stoppers.csv', 'w') as myfile:\n",
    "#     wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "#     wr.writerow([stoppers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load nltk's SnowballStemmer as variabled 'stemmer'\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Use regular expressions to do a find-and-replace\n",
    "# def tokenize_and_stem(text):\n",
    "#     # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
    "#     tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "#     filtered_tokens = []\n",
    "#     # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
    "#     for token in tokens:\n",
    "#         if re.search('[a-zA-Z]', token):\n",
    "#             filtered_tokens.append(token)\n",
    "#     stems = [stemmer.stem(t) for t in filtered_tokens]\n",
    "#     return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tv = TfidfVectorizer(strip_accents='ascii',\n",
    "                     max_df=0.8, \n",
    "                     max_features=200000,\n",
    "                     min_df=5,\n",
    "                     analyzer='word',\n",
    "                     stop_words=stoppers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@timefunc\n",
    "def vectorize(sample):\n",
    "    ts_vec = tv.fit_transform(sample)\n",
    "    df_ts = pd.DataFrame(ts_vec.todense(), columns=[tv.get_feature_names()])\n",
    "    return df_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectorize took 6.74557900428772 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(100000, 23701)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_vec = vectorize(comments)\n",
    "ts_vec.head()\n",
    "ts_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with open('final_comments_vec.pkl','wb') as picklefile:\n",
    "#     pickle.dump(ts_vec, picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with open('final_comments_vec.pkl','rb') as picklefile:\n",
    "#     ts_vec = pickle.load(picklefile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model with SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic #%d:\" % topic_idx)\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topics in LSA model:\n",
      "\n",
      "Explained variance ratio [ 0.00295218  0.00482     0.0042314   0.00418687  0.00337323  0.00310548\n",
      "  0.00298784  0.00266102  0.00259735  0.00253535]\n",
      "Topic #0:\n",
      "people talk like think great good really thank world know life time make need things want work amazing video point right better idea agree believe thing new thanks human said interesting years feel change use lot understand best help going\n",
      "Topic #1:\n",
      "thank great talk amazing inspiring wow thanks awesome sharing beautiful wonderful brilliant speech video nice presentation story loved excellent inspirational fantastic interesting inspiration enjoyed inspired absolutely truly informative talks message favorite fascinating best incredible powerful sir speaker mr watched brave\n",
      "Topic #2:\n",
      "amazing thank wow people like beautiful world life know sharing need god want human simply said think truly absolutely things technology story make woman right believe time person better wish wonderful live inspiring change words help look money true music\n",
      "Topic #3:\n",
      "amazing great talk wow thanks really speech awesome video idea presentation man technology interesting simply work woman absolutely speaker funny stuff watch truly performance cool pretty nice loved enjoyed talent seen wish thats audience fucking genius watched topic haha music\n",
      "Topic #4:\n",
      "good talk awesome nice point really interesting luck bad thanks inspiring enjoyed excellent loved stuff funny beautiful best liked topic evil points speaker goodcountry pretty watched vid welcome thing ha brilliant informative advice quite favorite book fantastic intentions title party\n",
      "Topic #5:\n",
      "awesome talk wow thanks like nice interesting inspiring video watch really talks com brilliant best http beautiful excellent cool www lol loved enjoyed absolutely wonderful seen favorite watched agree fucking fantastic youtube watching listen totally inspirational sharing html looks truly\n",
      "Topic #6:\n",
      "talk interesting inspiring nice brilliant best http com talks right women www excellent wonderful seen fantastic want enjoyed men loved agree world point html watch science favorite fascinating listen important believe different worst time subject end brain fact read informative\n",
      "Topic #7:\n",
      "thanks like video wow watch interesting com beautiful http www sharing inspiring youtube talks sounds looks nice watching really lot lol link comment brilliant wonderful html music org watched videos loved check presentation hi cool best speech feel know sound\n",
      "Topic #8:\n",
      "like really sounds looks nice good talk cool great interesting sound lol look idea video talks thank music watch youtube feel stuff beautiful com amazing voice http funny www feels accent kinda dislike liked dude yeah videos shit sounded wish\n",
      "Topic #9:\n",
      "wow nice really think beautiful people inspiring right interesting point speech world agree talk make better loved idea need incredible said speechless powerful word thought true words brilliant mind smart thinking money wrong thats different person makes music mean saying\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "topics = 10\n",
    "top_words = 40\n",
    "\n",
    "lsa = TruncatedSVD(n_components=topics,algorithm='randomized').fit(ts_vec)\n",
    "\n",
    "print(\"\\nTopics in LSA model:\")\n",
    "tfidf_feature_names = tv.get_feature_names()\n",
    "print(\"\\nExplained variance ratio\", lsa.explained_variance_ratio_)\n",
    "print(print_top_words(lsa, tfidf_feature_names, top_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('lsa_model.pkl','wb') as p:\n",
    "    pickle.dump(lsa,p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pick up pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('lsa_model.pkl','rb') as p:\n",
    "    lsa = pickle.load(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TruncatedSVD(algorithm='randomized', n_components=10, n_iter=5,\n",
       "       random_state=None, tol=0.0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.016524</td>\n",
       "      <td>-0.006253</td>\n",
       "      <td>0.002719</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>-0.003015</td>\n",
       "      <td>0.006835</td>\n",
       "      <td>-0.004977</td>\n",
       "      <td>-0.004460</td>\n",
       "      <td>-0.003085</td>\n",
       "      <td>-0.004221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.161739</td>\n",
       "      <td>0.053766</td>\n",
       "      <td>0.060058</td>\n",
       "      <td>-0.112828</td>\n",
       "      <td>0.124430</td>\n",
       "      <td>-0.086072</td>\n",
       "      <td>-0.071893</td>\n",
       "      <td>-0.037568</td>\n",
       "      <td>-0.022300</td>\n",
       "      <td>-0.015814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.108550</td>\n",
       "      <td>-0.047270</td>\n",
       "      <td>0.012682</td>\n",
       "      <td>-0.010828</td>\n",
       "      <td>-0.026289</td>\n",
       "      <td>-0.005126</td>\n",
       "      <td>0.007296</td>\n",
       "      <td>-0.025012</td>\n",
       "      <td>-0.030800</td>\n",
       "      <td>-0.008216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.070030</td>\n",
       "      <td>-0.021546</td>\n",
       "      <td>0.007528</td>\n",
       "      <td>-0.000834</td>\n",
       "      <td>-0.007299</td>\n",
       "      <td>0.003508</td>\n",
       "      <td>-0.005931</td>\n",
       "      <td>-0.004316</td>\n",
       "      <td>-0.003534</td>\n",
       "      <td>-0.007534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.014035</td>\n",
       "      <td>-0.000321</td>\n",
       "      <td>0.001313</td>\n",
       "      <td>-0.002434</td>\n",
       "      <td>-0.001320</td>\n",
       "      <td>0.002695</td>\n",
       "      <td>0.002846</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>-0.004900</td>\n",
       "      <td>0.003657</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.016524 -0.006253  0.002719  0.000004 -0.003015  0.006835 -0.004977   \n",
       "1  0.161739  0.053766  0.060058 -0.112828  0.124430 -0.086072 -0.071893   \n",
       "2  0.108550 -0.047270  0.012682 -0.010828 -0.026289 -0.005126  0.007296   \n",
       "3  0.070030 -0.021546  0.007528 -0.000834 -0.007299  0.003508 -0.005931   \n",
       "4  0.014035 -0.000321  0.001313 -0.002434 -0.001320  0.002695  0.002846   \n",
       "\n",
       "          7         8         9  \n",
       "0 -0.004460 -0.003085 -0.004221  \n",
       "1 -0.037568 -0.022300 -0.015814  \n",
       "2 -0.025012 -0.030800 -0.008216  \n",
       "3 -0.004316 -0.003534 -0.007534  \n",
       "4  0.000123 -0.004900  0.003657  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truncated_matrix = lsa.transform(ts_vec)\n",
    "trunc_features = pd.DataFrame(truncated_matrix)\n",
    "trunc_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 10)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trunc_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('svd_comments.pkl','wb') as picklefile:\n",
    "    pickle.dump(trunc_features, picklefile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pick up pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('svd_comments.pkl','rb') as picklefile:\n",
    "    trunc_features = pickle.load(picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('target.pkl','rb') as picklefile:\n",
    "    target = pickle.load(picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trunc_features['target'] = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.016524</td>\n",
       "      <td>-0.006253</td>\n",
       "      <td>0.002719</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>-0.003015</td>\n",
       "      <td>0.006835</td>\n",
       "      <td>-0.004977</td>\n",
       "      <td>-0.004460</td>\n",
       "      <td>-0.003085</td>\n",
       "      <td>-0.004221</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.161739</td>\n",
       "      <td>0.053766</td>\n",
       "      <td>0.060058</td>\n",
       "      <td>-0.112828</td>\n",
       "      <td>0.124430</td>\n",
       "      <td>-0.086072</td>\n",
       "      <td>-0.071893</td>\n",
       "      <td>-0.037568</td>\n",
       "      <td>-0.022300</td>\n",
       "      <td>-0.015814</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.108550</td>\n",
       "      <td>-0.047270</td>\n",
       "      <td>0.012682</td>\n",
       "      <td>-0.010828</td>\n",
       "      <td>-0.026289</td>\n",
       "      <td>-0.005126</td>\n",
       "      <td>0.007296</td>\n",
       "      <td>-0.025012</td>\n",
       "      <td>-0.030800</td>\n",
       "      <td>-0.008216</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.070030</td>\n",
       "      <td>-0.021546</td>\n",
       "      <td>0.007528</td>\n",
       "      <td>-0.000834</td>\n",
       "      <td>-0.007299</td>\n",
       "      <td>0.003508</td>\n",
       "      <td>-0.005931</td>\n",
       "      <td>-0.004316</td>\n",
       "      <td>-0.003534</td>\n",
       "      <td>-0.007534</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.014035</td>\n",
       "      <td>-0.000321</td>\n",
       "      <td>0.001313</td>\n",
       "      <td>-0.002434</td>\n",
       "      <td>-0.001320</td>\n",
       "      <td>0.002695</td>\n",
       "      <td>0.002846</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>-0.004900</td>\n",
       "      <td>0.003657</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.016524 -0.006253  0.002719  0.000004 -0.003015  0.006835 -0.004977   \n",
       "1  0.161739  0.053766  0.060058 -0.112828  0.124430 -0.086072 -0.071893   \n",
       "2  0.108550 -0.047270  0.012682 -0.010828 -0.026289 -0.005126  0.007296   \n",
       "3  0.070030 -0.021546  0.007528 -0.000834 -0.007299  0.003508 -0.005931   \n",
       "4  0.014035 -0.000321  0.001313 -0.002434 -0.001320  0.002695  0.002846   \n",
       "\n",
       "          7         8         9  target  \n",
       "0 -0.004460 -0.003085 -0.004221       0  \n",
       "1 -0.037568 -0.022300 -0.015814       1  \n",
       "2 -0.025012 -0.030800 -0.008216       0  \n",
       "3 -0.004316 -0.003534 -0.007534       0  \n",
       "4  0.000123 -0.004900  0.003657       0  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(trunc_features.shape)\n",
    "trunc_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TED_dist = trunc_features[trunc_features['target'] == 1]\n",
    "YT_dist = trunc_features[trunc_features['target'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60295, 11)\n",
      "(39705, 11)\n"
     ]
    }
   ],
   "source": [
    "print(TED_dist.shape)\n",
    "print(YT_dist.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TED_dist = TED_dist.drop('target',axis=1)\n",
    "YT_dist = YT_dist.drop('target',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.080702\n",
      "1   -0.003586\n",
      "2    0.003508\n",
      "3   -0.000470\n",
      "4   -0.001641\n",
      "5    0.002763\n",
      "6   -0.001242\n",
      "7    0.002664\n",
      "8   -0.002860\n",
      "9   -0.000450\n",
      "dtype: float64\n",
      "0    0.080418\n",
      "1   -0.003315\n",
      "2    0.004130\n",
      "3   -0.000334\n",
      "4   -0.001779\n",
      "5    0.002483\n",
      "6   -0.001337\n",
      "7    0.001947\n",
      "8   -0.002370\n",
      "9   -0.000314\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(TED_dist.mean())\n",
    "print(YT_dist.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.array(TED_dist.mean())\n",
    "y = np.array(YT_dist.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.08070192, -0.00358598,  0.00350844, -0.00047027, -0.00164102,\n",
       "        0.00276283, -0.0012423 ,  0.00266448, -0.00285986, -0.00045005])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
